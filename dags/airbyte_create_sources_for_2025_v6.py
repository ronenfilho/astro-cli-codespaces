from __future__ import annotations

import pendulum
from airflow.models.dag import DAG
from airflow.decorators import task

# =============================================================================
# FUN√á√ÉO AUXILIAR: Obter Token OAuth
# =============================================================================
def get_airbyte_oauth_token() -> tuple[str, str]:
    """
    Obt√©m token OAuth do Airbyte usando Client ID e Secret
    Retorna (access_token, base_url)
    """
    import requests
    from airflow.utils.log.logging_mixin import LoggingMixin
    from airflow.hooks.base import BaseHook
    
    log = LoggingMixin().log
    
    try:
        conn = BaseHook.get_connection('airbyte_api')
        client_secret = conn.password
        base_url = conn.host
        client_id = conn.extra_dejson.get('client_id') if conn.extra_dejson else None

        if not client_secret:
            raise ValueError("Client Secret n√£o configurado na conex√£o 'airbyte_api'")
        if not client_id:
            raise ValueError("Client ID n√£o configurado no extra da conex√£o 'airbyte_api'")
        
        # Obter token OAuth
        oauth_endpoint = f"{base_url}/v1/applications/token"
        oauth_payload = {
            "client_id": client_id,
            "client_secret": client_secret
        }
        
        oauth_headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        
        response = requests.post(oauth_endpoint, headers=oauth_headers, json=oauth_payload, timeout=30)
        
        if response.status_code != 200:
            raise Exception(f"OAuth falhou: {response.status_code} - {response.text}")
        
        oauth_data = response.json()
        access_token = oauth_data.get('access_token')
        
        if not access_token:
            raise Exception("Access token n√£o retornado pela API OAuth")
            
        log.info(f"‚úÖ Token OAuth obtido com sucesso: {access_token[:10]}...")
        return access_token, base_url
        
    except Exception as e:
        log.error(f"Falha ao obter token OAuth: {e}")
        raise

# =============================================================================
# TAREFA 1: Criar a Fonte no Airbyte
# =============================================================================
@task
def create_airbyte_source(month: str, year: str = "2024") -> str:
    """
    Cria uma fonte no Airbyte para um m√™s e ano espec√≠ficos.
    Retorna o sourceId gerado para uso na pr√≥xima tarefa.
    """
    import requests
    from airflow.utils.log.logging_mixin import LoggingMixin
    from airflow.hooks.base import BaseHook
    from airflow.models.variable import Variable

    log = LoggingMixin().log

    log.info(f"--- CRIANDO FONTE AIRBYTE PARA {year}-{month} ---")

    # Obter token OAuth
    access_token, base_url = get_airbyte_oauth_token()
    
    workspace_id = Variable.get("airbyte_workspace_id")
    definition_id = Variable.get("airbyte_source_definition_id")
    
    year_month = f"{year}_{month}"

    payload = {
        "name": f"DISPONIBILIDADE_USINA_{year_month} - ONS (AUT)",
        "workspaceId": workspace_id,
        "definitionId": definition_id,
        "configuration": {
            "format": "csv",
            "provider": { "storage": "HTTPS", "user_agent": False },
            "url": f"https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/disponibilidade_usina_ho/DISPONIBILIDADE_USINA_{year_month}.csv",
            "dataset_name": f"DISPONIBILIDADE_USINA_{year_month}",
            "reader_options": "{ \"delimiter\": \";\" }"
        }
    }

    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    endpoint = f"{base_url}/v1/sources"
    
    log.info(f"Enviando requisi√ß√£o POST para: {endpoint}")

    response = requests.post(endpoint, headers=headers, json=payload)

    if response.status_code == 200:
        result = response.json()
        source_id = result.get('sourceId')
        
        if not source_id:
            raise ValueError("Resposta da API n√£o cont√©m sourceId")
            
        log.info(f"Fonte criada com SUCESSO! SourceId: {source_id}")
        return source_id
    else:
        log.error(f"Falha ao criar fonte. Status: {response.status_code}")
        log.error(f"Resposta da API: {response.text}")
        response.raise_for_status()

# =============================================================================
# TAREFA 2: Criar a Conex√£o entre Fonte e Destino
# =============================================================================
@task
def create_airbyte_connection(source_id: str) -> str:
    """
    Cria a conex√£o entre a fonte criada e o destino Snowflake.
    Retorna o connectionId gerado.
    """
    import requests
    from airflow.utils.log.logging_mixin import LoggingMixin
    from airflow.hooks.base import BaseHook
    from airflow.models.variable import Variable

    log = LoggingMixin().log

    if not source_id or source_id == "None":
        raise ValueError(f"source_id inv√°lido: {source_id}")

    log.info(f"--- CRIANDO CONEX√ÉO PARA SOURCE_ID: {source_id} ---")

    # Obter token OAuth
    access_token, base_url = get_airbyte_oauth_token()
    
    destination_id = Variable.get("airbyte_destination_id_snowflake")
    
    # Validar se os IDs est√£o no formato UUID correto
    import re
    uuid_pattern = r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'
    
    if not re.match(uuid_pattern, source_id, re.IGNORECASE):
        raise ValueError(f"Source ID n√£o est√° no formato UUID v√°lido: {source_id}")
        
    if not re.match(uuid_pattern, destination_id, re.IGNORECASE):
        raise ValueError(f"Destination ID n√£o est√° no formato UUID v√°lido: {destination_id}")

    # Primeiro, vamos verificar se a fonte existe
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json",
        "Accept": "application/json"
    }
    
    # Verificar se a fonte existe
    source_endpoint = f"{base_url}/v1/sources/{source_id}"
    log.info(f"Verificando se a fonte existe: {source_endpoint}")
    
    source_response = requests.get(source_endpoint, headers=headers)
    if source_response.status_code != 200:
        log.error(f"Fonte n√£o encontrada. Status: {source_response.status_code}")
        log.error(f"Resposta: {source_response.text}")
        raise ValueError(f"Fonte {source_id} n√£o existe ou n√£o pode ser acessada")
    
    log.info("Fonte verificada com sucesso!")

    # Configura a conex√£o para ser 'manual' e 'ativa'
    payload = {
        "sourceId": source_id,
        "destinationId": destination_id,
        "status": "active",
        "scheduleType": "manual"  # Mudan√ßa aqui - scheduleType direto, n√£o aninhado
    }

    endpoint = f"{base_url}/v1/connections"
    
    log.info(f"Enviando requisi√ß√£o POST para: {endpoint}")
    log.info(f"Source ID: {source_id}")
    log.info(f"Destination ID: {destination_id}")
    log.info(f"Payload: {payload}")

    response = requests.post(endpoint, headers=headers, json=payload)

    if response.status_code == 200:
        result = response.json()
        connection_id = result.get('connectionId')
        
        if not connection_id:
            raise ValueError("Resposta da API n√£o cont√©m connectionId")
            
        log.info(f"Conex√£o criada com SUCESSO! ConnectionId: {connection_id}")
        return connection_id
    else:
        log.error(f"Falha ao criar conex√£o. Status: {response.status_code}")
        log.error(f"Resposta da API: {response.text}")
        
        # Verificar se √© conflito de stream (conex√£o j√° existe)
        if response.status_code == 400:
            response_data = response.json()
            if (response_data.get('type') == 'error:connection-conflicting-destination-stream' or 
                'conflicting stream' in response_data.get('detail', '').lower()):
                log.info("üéØ CONEX√ÉO J√Å EXISTE! Conflito de stream detectado - considerando como sucesso")
                # Retornar ID fict√≠cio para indicar sucesso (conex√£o j√° existe)
                return f"existing-connection-{source_id[-8:]}"
        
        # Tentar payload alternativo se o primeiro falhar
        if response.status_code == 403:
            log.info("Tentando payload alternativo...")
            payload_alt = {
                "sourceId": source_id,
                "destinationId": destination_id,
                "status": "active",
                "schedule": {
                    "scheduleType": "manual"
                }
            }
            
            response_alt = requests.post(endpoint, headers=headers, json=payload_alt)
            if response_alt.status_code == 200:
                result = response_alt.json()
                connection_id = result.get('connectionId')
                log.info(f"Conex√£o criada com payload alternativo! ConnectionId: {connection_id}")
                return connection_id
            else:
                log.error(f"Payload alternativo tamb√©m falhou. Status: {response_alt.status_code}")
                log.error(f"Resposta: {response_alt.text}")
        
        response.raise_for_status()

# =============================================================================
# DEFINI√á√ÉO DA DAG
# =============================================================================
with DAG(
    dag_id="airbyte_create_sources_for_2025_v6",
    start_date=pendulum.datetime(2025, 9, 25, tz="America/Sao_Paulo"),
    schedule=None,
    catchup=False,
    tags=["airbyte", "automation", "Inteligencia Energetica"],
    doc_md="""
    ### DAG para Cria√ß√£o de Fontes e Conex√µes no Airbyte - v6
    
    Esta DAG automatiza a cria√ß√£o de fontes e conex√µes no Airbyte para os √∫ltimos 3 meses de 2024 (agosto, setembro, outubro).
    
    **Fluxo de Trabalho:**
    1. **TAREFA 1**: Cria uma fonte no Airbyte para cada m√™s
    2. **TAREFA 2**: Cria uma conex√£o entre cada fonte e o destino Snowflake
    
    **Recursos:**
    - Busca arquivos de disponibilidade de usinas do ONS
    - Configura√ß√£o manual de sincroniza√ß√£o (n√£o autom√°tica)
    - Conex√µes ficam ativas mas precisam ser disparadas manualmente
    
    **Pr√©-requisitos:**
    1. Conex√£o HTTP `airbyte_api` configurada no Airflow
    2. Vari√°veis configuradas no Airflow:
       - `airbyte_workspace_id`
       - `airbyte_source_definition_id`
       - `airbyte_destination_id_snowflake`
    """
) as dag:
    
    # Gera a lista dos √∫ltimos 3 meses (outubro, setembro, agosto)
    months = ["10", "09", "08"]
    
    # Etapa 1: Mapeamento din√¢mico para criar as fontes
    source_ids = create_airbyte_source.expand(month=months)
    
    # Etapa 2: Mapeamento din√¢mico para criar as conex√µes,
    # dependendo da cria√ß√£o das fontes
    create_airbyte_connection.expand(source_id=source_ids)